{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Powered Retriever\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリのインストール。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境変数 `MY_OPENAI_API_KEY` に使用する API キーを設定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"MY_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_knowledge_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knowledge_string():\n",
    "    \"\"\"\n",
    "    data/ ディレクトリ以下のファイルをすべて読み込んで, 一つのテキストにして返す\n",
    "    ファイルごとに、ファイル名を文頭にわかりやすく追加する。\n",
    "\n",
    "    Returns:\n",
    "        str: テキスト\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    files = glob.glob('data/**', recursive=True)\n",
    "    files.sort()\n",
    "    text = ''\n",
    "\n",
    "    for file in files:\n",
    "        if os.path.isdir(file):\n",
    "            continue\n",
    "        with open(file, 'r') as f:\n",
    "            text += '---\\n'\n",
    "            text += f'# {file}\\n\\n'\n",
    "            text += f.read()\n",
    "            text += '\\n\\n'\n",
    "\n",
    "    print(f\"文字列の長さ: {len(text)}\")\n",
    "\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")\n",
    "    tokens = len(encoding.encode(text))\n",
    "    print(f\"トークン数: {tokens}\\n\")\n",
    "\n",
    "    if tokens >= 120000:\n",
    "        raise Exception('トークン数が120000を超えています。')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(question: str):\n",
    "    \"\"\"\n",
    "    LLM に入力するプロンプトを生成する\n",
    "\n",
    "    Args:\n",
    "        question (str): 質問\n",
    "\n",
    "    Returns:\n",
    "        str: プロンプト\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    {get_knowledge_string()}\n",
    "\n",
    "\n",
    "    上記のテキストを参考に質問に答えてください。\n",
    "\n",
    "    Q: {question}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データを削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_data:\n",
    "    import os\n",
    "    import glob\n",
    "    files = glob.glob('data/**', recursive=True)\n",
    "    for file in files:\n",
    "        if os.path.isdir(file):\n",
    "            continue\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ディレクトリからファイルを移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_download:\n",
    "    print('ダウンロードディレクトリの md ファイルを読み込みます')\n",
    "    !mkdir -p ./data\n",
    "    !mv ~/Downloads/*.md ./data/\n",
    "    !ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_download = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 質問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"\"\"\n",
    "GKE の料金体系について簡単に教えてください\n",
    "\"\"\"\n",
    "\n",
    "if question_enabled and question.strip() != '':\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    chat = ChatOpenAI(model='gpt-4-1106-preview')\n",
    "    print(chat.predict(generate_prompt(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_enabled = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
